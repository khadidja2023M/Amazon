{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9046a68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simple.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple.py\n",
    "import streamlit as st\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "from keras.models import load_model\n",
    "\n",
    "# Initialize global variables\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "max_length = 100\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"sentiment.h5\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "def preprocess_user_input(text):\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "\n",
    "    # Loading the tokenizer vocabulary\n",
    "    with open('tokenizer_vocabulary.json', 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        tokenizer = tokenizer_from_json(data)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    \n",
    "    # Check if the sequences are empty\n",
    "    if not sequences or not sequences[0]:\n",
    "        return None\n",
    "        \n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "    return padded_sequences\n",
    "\n",
    "def display_help_menu():\n",
    "    st.subheader(\"1. What is this application?\")\n",
    "    st.write(\"\"\"\n",
    "    This application analyzes the sentiment of any given text. \n",
    "    Just type in your text and the app will determine whether it's positive or negative.\n",
    "    \"\"\")\n",
    "\n",
    "    st.subheader(\"2. How to use?\")\n",
    "    st.write(\"\"\"\n",
    "    - Enter your text in the text area.\n",
    "    - Click on 'Predict' to get the sentiment.\n",
    "    \"\"\")\n",
    "\n",
    "    st.subheader(\"3. Troubleshooting\")\n",
    "    st.write(\"\"\"\n",
    "    If you encounter any issues:\n",
    "    - Try rephrasing your text.\n",
    "    - Ensure your text is in English.\n",
    "    - Check the format of your text.\n",
    "    \"\"\")\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"SentimAnalyzer\")\n",
    "st.sidebar.header(\"Menu\")\n",
    "help_option = st.sidebar.radio('Choose an option', ['Home', 'Help'])\n",
    "\n",
    "if help_option == 'Home':\n",
    "    user_text = st.text_area(\"Enter text for sentiment analysis:\")\n",
    "\n",
    "    if st.button('Predict'):\n",
    "        processed_input = preprocess_user_input(user_text)\n",
    "        \n",
    "        # Check if the processed_input is None and inform the user\n",
    "        if processed_input is None:\n",
    "            st.write(\"Unable to process the input text. Please try another.\")\n",
    "        else:\n",
    "            prediction = loaded_model.predict(processed_input)\n",
    "            sentiment = \"Positive\" if np.argmax(prediction) > 0.5 else \"Negative\"\n",
    "            st.write(f\"The text sentiment is: {sentiment}\")\n",
    "\n",
    "elif help_option == 'Help':\n",
    "    display_help_menu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c55342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run simple.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926db6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
